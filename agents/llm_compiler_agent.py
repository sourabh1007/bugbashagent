from typing import Dict, Any, List
import os
import subprocess
import re
from .base_agent import BaseAgent

class LLMCompilerAgent(BaseAgent):
    """
    Advanced LLM agent with compiler tools that:
    1. Compiles code generated by the Code Generator agent
    2. Analyzes each compilation error individually using LLM
    3. Returns an array of structured error objects with fix suggestions
    """
    
    def __init__(self, llm):
        super().__init__("LLM Compiler Agent", llm)
    
    def execute(self, input_data: Any) -> Dict[str, Any]:
        """
        Execute compilation and error analysis on generated code
        
        Expected input_data structure:
        - If dict with 'code_path' and 'language': direct compilation
        - If CodeGenerator output: extract code_path and language from it
        """
        try:
            # Extract code path and language from input
            code_path, language = self._extract_code_info(input_data)
            
            if not code_path or not os.path.isdir(code_path):
                return {
                    "agent": self.name,
                    "input": input_data,
                    "output": None,
                    "status": "error",
                    "error": f"Invalid or missing code_path: {code_path}"
                }
            
            self.log(f"Starting compilation of {language} code in: {code_path}")
            
            # Step 1: Compile the code
            compilation_result = self._compile_code(code_path, language)
            
            if compilation_result["status"] == "success":
                self.log("‚úÖ Code compiled successfully - no errors to analyze")
                return {
                    "agent": self.name,
                    "input": input_data,
                    "output": "Code compiled successfully with no errors",
                    "compilation_result": compilation_result,
                    "error_analysis": [],
                    "total_errors": 0,
                    "compilation_status": "success",
                    "code_path": code_path,
                    "language": language,
                    "status": "success"
                }
            
            # Step 2: Parse compilation errors (treat as expected outcome to analyze)
            self.log(f"üìã Compilation has errors - analyzing them for insights...")
            raw_errors = compilation_result.get("errors", "")
            parsed_errors = self._parse_compilation_errors(raw_errors, language)
            
            self.log(f"üìä Found {len(parsed_errors)} compilation errors to analyze")
            
            # Step 3: Use LLM to analyze all errors together and suggest consolidated fixes
            consolidated_analysis = self._analyze_all_errors_with_llm(parsed_errors, language, code_path, compilation_result)
            
            # Structure output as JSON for another agent to consume
            json_output = {
                "compilation_status": "failed",
                "errors_found": True,
                "total_errors": len(parsed_errors),
                "language": language,
                "code_path": code_path,
                "compilation_command": compilation_result.get("command", "Unknown"),
                "error_categories": consolidated_analysis.get("error_categories", {}),
                "priority_breakdown": self._create_priority_breakdown(consolidated_analysis.get("error_categories", {})),
                "actionable_fixes": {
                    "step_by_step_plan": consolidated_analysis.get("step_by_step_plan", []),
                    "consolidated_fixes": consolidated_analysis.get("consolidated_fixes", []),
                    "priority_order": self._get_fix_priority_order(consolidated_analysis.get("error_categories", {}))
                },
                "summary": {
                    "overview": consolidated_analysis.get("error_summary", ""),
                    "key_issues": self._extract_key_issues(consolidated_analysis.get("error_categories", {})),
                    "estimated_fix_time": self._estimate_fix_time(len(parsed_errors), consolidated_analysis.get("error_categories", {})),
                    "complexity_level": self._assess_complexity(consolidated_analysis.get("error_categories", {}))
                },
                "detailed_analysis": {
                    "llm_analysis": consolidated_analysis.get("llm_full_analysis", ""),
                    "raw_compilation_output": compilation_result.get("stderr", "") or compilation_result.get("stdout", ""),
                    "compilation_exit_code": compilation_result.get("returncode", -1)
                },
                "next_actions": self._generate_next_actions(consolidated_analysis),
                "metadata": {
                    "analysis_timestamp": compilation_result.get("timestamp", ""),
                    "agent": self.name,
                    "analysis_version": "consolidated_v2"
                }
            }
            
            return {
                "agent": self.name,
                "input": input_data,
                "output": json_output,
                "compilation_result": compilation_result,
                "error_analysis": consolidated_analysis,
                "total_errors": len(parsed_errors),
                "compilation_status": "has_errors",
                "code_path": code_path,
                "language": language,
                "status": "success"  # Always success - errors are just data to analyze
            }
            
        except Exception as e:
            self.log(f"‚ùå Error during LLM compilation analysis: {str(e)}")
            return {
                "agent": self.name,
                "input": input_data,
                "output": None,
                "status": "error",
                "error": str(e)
            }
    
    def _extract_code_info(self, input_data: Any) -> tuple:
        """Extract code_path and language from various input formats"""
        if isinstance(input_data, dict):
            # Direct input with code_path and language
            if "code_path" in input_data and "language" in input_data:
                return input_data["code_path"], input_data["language"]
            
            # CodeGenerator output format
            if "output" in input_data and isinstance(input_data["output"], dict):
                code_generator_output = input_data["output"]
                return code_generator_output.get("code_path"), code_generator_output.get("language")
            
            # Check if it's the output dict itself
            if "code_path" in input_data:
                return input_data.get("code_path"), input_data.get("language")
        
        return None, None
    
    def _compile_code(self, code_path: str, language: str) -> Dict[str, Any]:
        """Compile the code and return compilation results"""
        self.log(f"üî® Starting compilation for {language} in directory: {code_path}")
        
        compile_cmd = self._get_compile_command(language, code_path)
        if not compile_cmd:
            self.log(f"‚ùå Unsupported language: {language}")
            return {
                "status": "error",
                "error": f"Unsupported language: {language}"
            }
        
        cmd_str = " ".join(compile_cmd) if isinstance(compile_cmd, list) else compile_cmd
        self.log(f"üìã Compilation command: {cmd_str}")
        self.log(f"üìÅ Working directory: {code_path}")
        
        try:
            self.log(f"‚ö° Executing compilation command...")
            proc = subprocess.run(compile_cmd, capture_output=True, text=True, cwd=code_path)
            
            self.log(f"‚úÖ Command execution completed with return code: {proc.returncode}")
            
            if proc.stdout:
                self.log(f"üì§ STDOUT ({len(proc.stdout)} chars): {proc.stdout[:200]}{'...' if len(proc.stdout) > 200 else ''}")
            else:
                self.log(f"üì§ STDOUT: (empty)")
                
            if proc.stderr:
                self.log(f"üì• STDERR ({len(proc.stderr)} chars): {proc.stderr[:200]}{'...' if len(proc.stderr) > 200 else ''}")
            else:
                self.log(f"üì• STDERR: (empty)")
            
            if proc.returncode == 0:
                self.log(f"üéâ Compilation successful!")
            else:
                self.log(f"‚ö†Ô∏è Compilation failed with return code {proc.returncode}")
            
            # For some compilers (like dotnet), errors might be in stdout instead of stderr
            error_output = proc.stderr
            if not error_output.strip() and proc.returncode != 0:
                # If stderr is empty but compilation failed, check stdout for errors
                self.log(f"üîç No errors in stderr, checking stdout for error messages...")
                if any(keyword in proc.stdout.lower() for keyword in ['error', 'failed', 'exception']):
                    error_output = proc.stdout
                    self.log(f"üìã Found error indicators in stdout, using it as error output")
            
            return {
                "status": "success" if proc.returncode == 0 else "compilation_error",
                "returncode": proc.returncode,
                "stdout": proc.stdout,
                "stderr": proc.stderr,
                "errors": error_output,  # This will be the primary error source for parsing
                "command": cmd_str
            }
        except Exception as e:
            self.log(f"üí• Compilation execution failed: {str(e)}")
            return {
                "status": "error",
                "error": f"Compilation execution failed: {str(e)}"
            }
    
    def _get_compile_command(self, language: str, code_path: str):
        """Get compilation command for the specified language"""
        self.log(f"üîç Detecting compilation command for {language} in {code_path}")
        
        if language in ["python"]:
            # Syntax check all .py files
            py_files = []
            for root, _, files in os.walk(code_path):
                for file in files:
                    if file.endswith('.py'):
                        py_files.append(os.path.relpath(os.path.join(root, file), code_path))
            
            self.log(f"üêç Found {len(py_files)} Python files: {py_files}")
            if not py_files:
                self.log(f"‚ùå No Python files found in {code_path}")
                return None
            return ["python", "-m", "py_compile"] + py_files
        
        elif language in ["csharp", "c#"]:
            self.log(f"üî∑ Using dotnet build for C# compilation")
            return ["dotnet", "build"]
        
        elif language in ["java"]:
            java_files = []
            for root, _, files in os.walk(code_path):
                for file in files:
                    if file.endswith('.java'):
                        java_files.append(os.path.relpath(os.path.join(root, file), code_path))
            
            self.log(f"‚òï Found {len(java_files)} Java files: {java_files}")
            if not java_files:
                self.log(f"‚ùå No Java files found in {code_path}")
                return None
            return ["javac"] + java_files
        
        elif language in ["javascript", "js", "node.js"]:
            js_files = []
            for root, _, files in os.walk(code_path):
                for file in files:
                    if file.endswith('.js'):
                        js_files.append(os.path.relpath(os.path.join(root, file), code_path))
            
            self.log(f"üü® Found {len(js_files)} JavaScript files: {js_files}")
            if not js_files:
                self.log(f"‚ùå No JavaScript files found in {code_path}")
                return None
            return ["node", "--check", js_files[0]]  # Check first file
        
        elif language in ["go"]:
            self.log(f"üîµ Using go build for Go compilation")
            return ["go", "build", "./..."]
        
        elif language in ["rust"]:
            self.log(f"ü¶Ä Using cargo check for Rust compilation")
            return ["cargo", "check"]
        
        else:
            self.log(f"‚ùå Unsupported language: {language}")
            return None
    
    def _parse_compilation_errors(self, raw_errors: str, language: str) -> List[Dict[str, Any]]:
        """Parse raw compilation errors into structured objects"""
        self.log(f"üîç Parsing compilation errors for {language}")
        self.log(f"üìù Raw error text length: {len(raw_errors)} characters")
        
        if not raw_errors.strip():
            self.log(f"‚ö†Ô∏è No error text to parse")
            return []
        
        error_objects = []
        
        # Language-specific error parsing patterns
        patterns = {
            "csharp": [
                # Standard dotnet build error format
                r"(?P<file>[^(]+)\((?P<line>\d+),(?P<col>\d+)\):\s*(?P<severity>error|warning)\s*(?P<code>\w+):\s*(?P<message>.+)",
                # Alternative format
                r"(?P<file>[^:]+):\s*(?P<severity>error|warning)\s*(?P<code>\w+):\s*(?P<message>.+)",
                # Simple error format
                r"(?P<severity>error|warning)\s*(?P<code>\w+):\s*(?P<message>.+)",
                # Generic error line
                r".*error.*:\s*(?P<message>.+)"
            ],
            "c#": [
                r"(?P<file>[^(]+)\((?P<line>\d+),(?P<col>\d+)\):\s*(?P<severity>error|warning)\s*(?P<code>\w+):\s*(?P<message>.+)",
                r"(?P<file>[^:]+):\s*(?P<severity>error|warning)\s*(?P<code>\w+):\s*(?P<message>.+)",
                r"(?P<severity>error|warning)\s*(?P<code>\w+):\s*(?P<message>.+)",
                r".*error.*:\s*(?P<message>.+)"
            ],
            "python": [
                r"File \"(?P<file>[^\"]+)\", line (?P<line>\d+).*\n\s*(?P<message>.+)",
                r"(?P<file>[^:]+):(?P<line>\d+):\s*(?P<message>.+)"
            ],
            "java": [
                r"(?P<file>[^:]+):(?P<line>\d+):\s*(?P<severity>error|warning):\s*(?P<message>.+)"
            ],
            "javascript": [
                r"(?P<file>[^:]+):(?P<line>\d+)\s*(?P<message>.+)"
            ]
        }
        
        # Get patterns for the language
        lang_patterns = patterns.get(language, patterns.get("csharp", []))
        self.log(f"üìã Using {len(lang_patterns)} patterns for {language}")
        
        lines = raw_errors.split('\n')
        self.log(f"üìÑ Processing {len(lines)} lines of error output")
        
        i = 0
        parsed_count = 0
        
        while i < len(lines):
            line = lines[i].strip()
            if not line:
                i += 1
                continue
            
            matched = False
            for pattern_idx, pattern in enumerate(lang_patterns):
                match = re.search(pattern, line, re.MULTILINE | re.IGNORECASE)
                if match:
                    self.log(f"‚úÖ Matched pattern {pattern_idx + 1} for line: {line[:50]}...")
                    
                    error_obj = {
                        "raw_line": line,
                        "file": match.group("file") if "file" in match.groupdict() and match.group("file") else "unknown",
                        "line": int(match.group("line")) if "line" in match.groupdict() and match.group("line") else 0,
                        "column": int(match.group("col")) if "col" in match.groupdict() and match.group("col") else 0,
                        "severity": match.group("severity") if "severity" in match.groupdict() and match.group("severity") else "error",
                        "code": match.group("code") if "code" in match.groupdict() and match.group("code") else "",
                        "message": match.group("message") if "message" in match.groupdict() and match.group("message") else line,
                        "context_lines": []
                    }
                    
                    # Collect context lines (next few lines that might be part of the error)
                    for j in range(i + 1, min(i + 4, len(lines))):
                        context_line = lines[j].strip()
                        if context_line and not any(re.search(p, context_line, re.IGNORECASE) for p in lang_patterns):
                            error_obj["context_lines"].append(context_line)
                        else:
                            break
                    
                    error_objects.append(error_obj)
                    parsed_count += 1
                    matched = True
                    break
            
            if not matched and line and any(keyword in line.lower() for keyword in ['error', 'failed', 'exception']):
                # Generic error object for unparsed error lines
                self.log(f"‚ö†Ô∏è Unparsed error line: {line[:50]}...")
                error_objects.append({
                    "raw_line": line,
                    "file": "unknown",
                    "line": 0,
                    "column": 0,
                    "severity": "error",
                    "code": "",
                    "message": line,
                    "context_lines": []
                })
                parsed_count += 1
            
            i += 1
        
        self.log(f"üìä Parsed {parsed_count} error objects from {len(lines)} lines")
        return error_objects
    
    def _analyze_all_errors_with_llm(self, parsed_errors: List[Dict[str, Any]], language: str, code_path: str, compilation_result: Dict[str, Any]) -> Dict[str, Any]:
        """Use LLM to analyze all compilation errors together and provide consolidated fix plan"""
        
        if not parsed_errors:
            return {
                "summary": "Code compiled successfully with no errors detected.",
                "error_summary": [],
                "consolidated_fixes": [],
                "step_by_step_plan": []
            }
        
        self.log(f"üîç Analyzing all {len(parsed_errors)} compilation errors together for consolidated fixes...")
        
        # Categorize and summarize errors
        error_categories = self._categorize_all_errors(parsed_errors)
        error_summary = self._create_error_summary(parsed_errors, error_categories)
        
        # Get sample code contexts for major error types
        sample_contexts = self._get_sample_code_contexts(parsed_errors, code_path)
        
        # Create consolidated analysis prompt
        analysis_prompt = self._create_consolidated_analysis_prompt(
            parsed_errors, error_categories, error_summary, sample_contexts, language, compilation_result
        )
        
        try:
            # Get LLM analysis for all errors
            self.log(f"üí≠ Requesting consolidated analysis from LLM...")
            llm_analysis = self.llm.invoke(analysis_prompt)
            llm_response = llm_analysis.content if hasattr(llm_analysis, 'content') else str(llm_analysis)
            
            # Extract step-by-step fixes from the response
            step_by_step_plan = self._extract_step_by_step_plan(llm_response)
            consolidated_fixes = self._extract_consolidated_fixes(llm_response)
            
            # Create final summary
            summary = self._create_final_summary(parsed_errors, error_categories, step_by_step_plan, compilation_result)
            
            return {
                "summary": summary,
                "error_summary": error_summary,
                "error_categories": error_categories,
                "consolidated_fixes": consolidated_fixes,
                "step_by_step_plan": step_by_step_plan,
                "llm_full_analysis": llm_response,
                "total_errors": len(parsed_errors),
                "compilation_command": compilation_result.get("command", "Unknown")
            }
            
        except Exception as e:
            self.log(f"‚ùå Error during consolidated analysis: {str(e)}")
            return {
                "summary": f"Failed to analyze {len(parsed_errors)} compilation errors: {str(e)}",
                "error_summary": error_summary,
                "error_categories": error_categories,
                "consolidated_fixes": ["Manual review required due to analysis failure"],
                "step_by_step_plan": ["1. Review compilation errors manually", "2. Fix issues individually"],
                "llm_full_analysis": f"Analysis failed: {str(e)}",
                "total_errors": len(parsed_errors),
                "compilation_command": compilation_result.get("command", "Unknown")
            }
    
    def _categorize_all_errors(self, parsed_errors: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """Categorize all errors by type"""
        categories = {}
        
        for error in parsed_errors:
            category = self._categorize_single_error(error)
            if category not in categories:
                categories[category] = []
            categories[category].append(error)
        
        return categories
    
    def _categorize_single_error(self, error: Dict[str, Any]) -> str:
        """Categorize a single error"""
        message = error.get('message', '').lower()
        
        category_keywords = {
            'using_imports': ['using clause must precede', 'using directive', 'namespace', 'import'],
            'syntax': ['syntax', 'expected', 'missing', 'unexpected', 'invalid token'],
            'type_errors': ['type', 'cannot convert', 'incompatible', 'does not exist in'],
            'reference_errors': ['not found', 'undefined', 'undeclared', 'does not exist'],
            'access_errors': ['access', 'private', 'protected', 'visibility', 'inaccessible'],
            'generic_errors': ['generic', 'type parameter', 'constraint']
        }
        
        for category, keywords in category_keywords.items():
            if any(keyword in message for keyword in keywords):
                return category
        
        return 'other'
    
    def _create_error_summary(self, parsed_errors: List[Dict[str, Any]], error_categories: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """Create a summary of all errors by category"""
        summary = []
        
        for category, errors in error_categories.items():
            # Get unique files affected
            affected_files = list(set(error.get('file', 'unknown') for error in errors))
            
            # Get sample error messages
            sample_messages = list(set(error.get('message', 'Unknown error') for error in errors))[:3]
            
            summary.append({
                "category": category,
                "count": len(errors),
                "affected_files": affected_files,
                "sample_messages": sample_messages,
                "severity": "high" if len(errors) > 10 or category in ['syntax', 'type_errors'] else "medium"
            })
        
        # Sort by count (most frequent first)
        summary.sort(key=lambda x: x['count'], reverse=True)
        return summary
    
    def _get_sample_code_contexts(self, parsed_errors: List[Dict[str, Any]], code_path: str) -> Dict[str, str]:
        """Get sample code contexts for different error types"""
        contexts = {}
        
        # Get one example for each major error type
        seen_categories = set()
        for error in parsed_errors[:10]:  # Limit to first 10 for performance
            category = self._categorize_single_error(error)
            if category not in seen_categories:
                context = self._get_code_context(error, code_path)
                if context != "No code context available":
                    contexts[category] = context
                    seen_categories.add(category)
        
        return contexts
    
    def _create_consolidated_analysis_prompt(self, parsed_errors: List[Dict[str, Any]], error_categories: Dict[str, List[Dict[str, Any]]], 
                                           error_summary: List[Dict[str, Any]], sample_contexts: Dict[str, str], 
                                           language: str, compilation_result: Dict[str, Any]) -> str:
        """Create a comprehensive prompt for consolidated error analysis"""
        
        prompt_parts = [
            f"You are an expert {language.upper()} developer tasked with analyzing compilation errors and providing a consolidated fix plan.",
            f"",
            f"COMPILATION DETAILS:",
            f"Language: {language}",
            f"Command: {compilation_result.get('command', 'Unknown')}",
            f"Total Errors: {len(parsed_errors)}",
            f"Return Code: {compilation_result.get('returncode', 'Unknown')}",
            f"",
            f"ERROR SUMMARY BY CATEGORY:",
        ]
        
        for summary in error_summary:
            prompt_parts.extend([
                f"- {summary['category'].upper()}: {summary['count']} errors",
                f"  Files affected: {', '.join(summary['affected_files'][:3])}{'...' if len(summary['affected_files']) > 3 else ''}",
                f"  Sample messages: {'; '.join(summary['sample_messages'])}",
                f""
            ])
        
        if sample_contexts:
            prompt_parts.extend([
                f"SAMPLE CODE CONTEXTS:",
                f""
            ])
            for category, context in sample_contexts.items():
                prompt_parts.extend([
                    f"{category.upper()} Example:",
                    f"```",
                    context[:500] + "..." if len(context) > 500 else context,
                    f"```",
                    f""
                ])
        
        prompt_parts.extend([
            f"Please provide a comprehensive analysis with:",
            f"",
            f"## 1. ROOT CAUSE ANALYSIS",
            f"Identify the main underlying issues causing these compilation errors.",
            f"",
            f"## 2. CONSOLIDATED FIX STRATEGY", 
            f"Provide an efficient strategy to fix all errors with minimal code changes.",
            f"",
            f"## 3. STEP-BY-STEP EXECUTION PLAN",
            f"Provide a clear, ordered list of steps to fix all compilation errors:",
            f"Step 1: [Most critical/foundational fix]",
            f"Step 2: [Next priority fix]", 
            f"Step 3: [Continue with remaining fixes]",
            f"...",
            f"",
            f"## 4. EXPECTED OUTCOME",
            f"Describe what should happen after implementing all fixes.",
            f"",
            f"## 5. PREVENTION TIPS",
            f"How to avoid these errors in future code generation.",
            f"",
            f"Focus on providing actionable, specific guidance that addresses the root causes efficiently."
        ])
        
        return "\n".join(prompt_parts)
    
    def _extract_step_by_step_plan(self, llm_response: str) -> List[str]:
        """Extract step-by-step plan from LLM response"""
        steps = []
        lines = llm_response.split('\n')
        
        in_steps_section = False
        for line in lines:
            line = line.strip()
            
            # Look for step-by-step section
            if any(keyword in line.lower() for keyword in ['step-by-step', 'execution plan', 'fix plan']):
                in_steps_section = True
                continue
            
            # Stop if we hit another section
            if line.startswith('##') and in_steps_section:
                break
            
            # Extract steps
            if in_steps_section and line:
                if line.lower().startswith('step ') or any(line.startswith(prefix) for prefix in ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '-']):
                    # Clean up the step
                    step = line
                    if ':' in step:
                        step = step.split(':', 1)[1].strip()
                    steps.append(step)
        
        # If no structured steps found, look for numbered items anywhere
        if not steps:
            for line in lines:
                line = line.strip()
                if any(line.startswith(prefix) for prefix in ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.']):
                    steps.append(line.split('.', 1)[1].strip())
        
        return steps[:10]  # Limit to 10 steps
    
    def _extract_consolidated_fixes(self, llm_response: str) -> List[str]:
        """Extract consolidated fixes from LLM response"""
        fixes = []
        lines = llm_response.split('\n')
        
        # Look for fix strategy section
        in_fix_section = False
        for line in lines:
            line = line.strip()
            
            if any(keyword in line.lower() for keyword in ['fix strategy', 'consolidated fix', 'fix approach']):
                in_fix_section = True
                continue
            
            if line.startswith('##') and in_fix_section:
                break
            
            if in_fix_section and line and (line.startswith('-') or line.startswith('*') or any(line.startswith(str(i)) for i in range(1, 10))):
                fixes.append(line.lstrip('-*123456789. '))
        
        return fixes[:8]  # Limit to 8 main fixes
    
    def _create_final_summary(self, parsed_errors: List[Dict[str, Any]], error_categories: Dict[str, List[Dict[str, Any]]], 
                            step_by_step_plan: List[str], compilation_result: Dict[str, Any]) -> str:
        """Create the final summary output"""
        
        # Calculate severity distribution
        high_priority_categories = ['using_imports', 'syntax', 'type_errors']
        high_priority_count = sum(len(errors) for cat, errors in error_categories.items() if cat in high_priority_categories)
        
        summary_parts = [
            f"CONSOLIDATED COMPILATION ERROR ANALYSIS",
            f"======================================",
            f"",
            f"üìä OVERVIEW:",
            f"- Total Errors: {len(parsed_errors)}",
            f"- Error Categories: {len(error_categories)}",
            f"- High Priority: {high_priority_count}",
            f"- Compilation Command: {compilation_result.get('command', 'Unknown')}",
            f"",
            f"üî• ERROR BREAKDOWN:"
        ]
        
        for category, errors in sorted(error_categories.items(), key=lambda x: len(x[1]), reverse=True):
            summary_parts.append(f"- {category.replace('_', ' ').title()}: {len(errors)} errors")
        
        if step_by_step_plan:
            summary_parts.extend([
                f"",
                f"üîß STEP-BY-STEP FIX PLAN:",
                f""
            ])
            for i, step in enumerate(step_by_step_plan, 1):
                summary_parts.append(f"{i}. {step}")
        
        summary_parts.extend([
            f"",
            f"üí° NEXT ACTIONS:",
            f"1. Follow the step-by-step plan above",
            f"2. Test compilation after each major step",
            f"3. Focus on high-priority categories first",
            f"4. Use the detailed analysis for specific guidance",
            f"",
            f"üìã Full analysis and specific fixes available in error_analysis field."
        ])
        
        return "\n".join(summary_parts)
        """Get relevant code context around the error location"""
        file_path = error.get("file", "")
        line_num = error.get("line", 0)
        
        if not file_path or line_num == 0:
            return "No code context available"
        
        try:
            # Try to read the file
            full_file_path = os.path.join(code_path, file_path) if not os.path.isabs(file_path) else file_path
            
            if not os.path.exists(full_file_path):
                return f"File not found: {file_path}"
            
            with open(full_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Get context around the error line (5 lines before and after)
            start_line = max(0, line_num - 6)
            end_line = min(len(lines), line_num + 5)
            
            context_lines = []
            for i in range(start_line, end_line):
                prefix = ">>> " if i == line_num - 1 else "    "
                context_lines.append(f"{prefix}{i+1:3d}: {lines[i].rstrip()}")
            
            return "\n".join(context_lines)
            
        except Exception as e:
            return f"Error reading file context: {str(e)}"
    
    def _create_error_analysis_prompt(self, error: Dict[str, Any], language: str, code_context: str) -> str:
        """Create a detailed prompt for LLM error analysis"""
        return f"""You are an expert {language.upper()} developer and compiler error analyst. 

COMPILATION ERROR DETAILS:
File: {error.get('file', 'unknown')}
Line: {error.get('line', 'unknown')}
Column: {error.get('column', 'unknown')}
Severity: {error.get('severity', 'error')}
Error Code: {error.get('code', 'N/A')}
Message: {error.get('message', 'Unknown error')}

CODE CONTEXT:
{code_context}

ADDITIONAL CONTEXT:
{chr(10).join(error.get('context_lines', []))}

Please provide a comprehensive analysis including:

1. **Error Explanation**: What exactly is causing this compilation error?
2. **Root Cause**: Why did this error occur in the context of the code?
3. **Fix Suggestion**: Provide a specific, actionable fix for this error
4. **Code Example**: Show the corrected code if applicable
5. **Prevention**: How to avoid this error in the future

Format your response clearly with these sections."""
    
    def _extract_fix_from_analysis(self, llm_response: str) -> str:
        """Extract the main fix suggestion from LLM analysis"""
        # Look for fix-related sections in the response
        fix_keywords = ["fix suggestion", "fix:", "solution:", "to fix", "correct"]
        lines = llm_response.split('\n')
        
        fix_lines = []
        capture_fix = False
        
        for line in lines:
            lower_line = line.lower().strip()
            
            if any(keyword in lower_line for keyword in fix_keywords):
                capture_fix = True
                if ":" in line:
                    fix_lines.append(line.split(":", 1)[1].strip())
                else:
                    fix_lines.append(line.strip())
                continue
            
            if capture_fix:
                if line.strip() and not line.startswith('#') and not line.startswith('**'):
                    fix_lines.append(line.strip())
                elif line.strip().startswith('**') or line.strip().startswith('#'):
                    break
        
        return " ".join(fix_lines) if fix_lines else "See full analysis for fix details"
    
    def _categorize_error(self, error: Dict[str, Any], llm_response: str) -> str:
        """Categorize the error type"""
        message = error.get('message', '').lower()
        
        categories = {
            'syntax': ['syntax', 'expected', 'missing', 'unexpected'],
            'type': ['type', 'cannot convert', 'incompatible'],
            'reference': ['not found', 'undefined', 'undeclared', 'does not exist'],
            'import': ['import', 'using', 'namespace', 'module'],
            'access': ['access', 'private', 'protected', 'visibility'],
            'generic': ['generic', 'type parameter', 'constraint']
        }
        
        for category, keywords in categories.items():
            if any(keyword in message for keyword in keywords):
                return category
        
        return 'other'
    
    def _assess_severity(self, error: Dict[str, Any], llm_response: str) -> str:
        """Assess the severity of the error"""
        severity = error.get('severity', 'error').lower()
        
        if severity == 'warning':
            return 'low'
        elif severity == 'error':
            # Check if it's a critical error based on message
            message = error.get('message', '').lower()
            critical_indicators = ['fatal', 'cannot continue', 'compilation terminated']
            
            if any(indicator in message for indicator in critical_indicators):
                return 'critical'
            else:
                return 'high'
        
        return 'medium'
    
    def _create_analysis_summary(self, error_analysis: List[Dict[str, Any]], compilation_result: Dict[str, Any]) -> str:
        """Create a comprehensive summary of the compilation analysis for downstream agents"""
        if not error_analysis:
            return "Code compiled successfully with no errors detected."
        
        # Categorize errors by type and severity
        error_categories = {}
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "unknown": 0}
        
        for analysis in error_analysis:
            category = analysis.get("error_category", "other")
            severity = analysis.get("severity_assessment", "unknown")
            
            if category not in error_categories:
                error_categories[category] = []
            error_categories[category].append(analysis)
            
            if severity in severity_counts:
                severity_counts[severity] += 1
        
        # Build comprehensive summary with detailed error list
        summary_parts = [
            f"COMPILATION ANALYSIS COMPLETE",
            f"============================",
            f"",
            f"üìä SUMMARY:",
            f"- Total errors analyzed: {len(error_analysis)}",
            f"- Error categories: {len(error_categories)}",
            f"- Compilation command: {compilation_result.get('command', 'Unknown')}",
            f"",
            f"üî• SEVERITY BREAKDOWN:",
            f"- Critical: {severity_counts['critical']}",
            f"- High: {severity_counts['high']}",
            f"- Medium: {severity_counts['medium']}",
            f"- Low: {severity_counts['low']}",
            f"- Unknown: {severity_counts['unknown']}",
            f"",
            f"üìÇ ERROR CATEGORIES:"
        ]
        
        for category, errors in error_categories.items():
            summary_parts.append(f"- {category.upper()}: {len(errors)} errors")
        
        # Add detailed error list with solutions
        summary_parts.extend([
            f"",
            f"üîç DETAILED ERROR ANALYSIS WITH SOLUTIONS:",
            f"==========================================",
            f""
        ])
        
        for i, analysis in enumerate(error_analysis, 1):
            original_error = analysis["original_error"]
            file_path = original_error.get("file", "unknown")
            line_num = original_error.get("line", "?")
            error_msg = original_error.get("message", "Unknown error")
            suggested_fix = analysis.get("suggested_fix", "No fix suggestion available")
            
            summary_parts.extend([
                f"ERROR #{i}:",
                f"----------",
                f"üìÑ File: {file_path}",
                f"üìç Line: {line_num}",
                f"‚ùå Error: {error_msg}",
                f"üîß Suggested Fix: {suggested_fix}",
                f"üìä Category: {analysis.get('error_category', 'unknown')}",
                f"‚ö†Ô∏è Severity: {analysis.get('severity_assessment', 'unknown')}",
                f""
            ])
            
            # Add LLM analysis excerpt if available
            llm_analysis = analysis.get("llm_analysis", "")
            if llm_analysis and len(llm_analysis) > 100:
                # Extract key insights from LLM analysis
                lines = llm_analysis.split('\n')
                key_insights = []
                for line in lines[:10]:  # First 10 lines usually contain the main insights
                    if line.strip() and not line.startswith('#') and len(line.strip()) > 20:
                        key_insights.append(f"  ‚Ä¢ {line.strip()}")
                
                if key_insights:
                    summary_parts.extend([
                        f"üí° Key Insights:",
                        *key_insights[:3],  # Show top 3 insights
                        f""
                    ])
        
        summary_parts.extend([
            f"üîß RECOMMENDED ACTIONS:",
            f"1. Review {severity_counts['critical'] + severity_counts['high']} high-priority errors first",
            f"2. Focus on {list(error_categories.keys())[0] if error_categories else 'syntax'} errors as they are most common",
            f"3. Check file dependencies and imports",
            f"4. Verify language-specific syntax and conventions",
            f"",
            f"üí° Complete detailed analysis available in error_analysis field for programmatic access."
        ])
        
        return "\n".join(summary_parts)
    
    def _get_code_context(self, error: Dict[str, Any], code_path: str) -> str:
        """Get relevant code context around the error location"""
        file_path = error.get("file", "")
        line_num = error.get("line", 0)
        
        if not file_path or line_num == 0:
            return "No code context available"
        
        try:
            # Try to read the file
            full_file_path = os.path.join(code_path, file_path) if not os.path.isabs(file_path) else file_path
            
            if not os.path.exists(full_file_path):
                return f"File not found: {file_path}"
            
            with open(full_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Get context around the error line (5 lines before and after)
            start_line = max(0, line_num - 6)
            end_line = min(len(lines), line_num + 5)
            
            context_lines = []
            for i in range(start_line, end_line):
                prefix = ">>> " if i == line_num - 1 else "    "
                context_lines.append(f"{prefix}{i+1:3d}: {lines[i].rstrip()}")
            
            return "\n".join(context_lines)
            
        except Exception as e:
            return f"Error reading file context: {str(e)}"

    def _create_priority_breakdown(self, error_categories):
        """Create priority breakdown for errors"""
        priority_mapping = {
            "using_imports": "high",
            "syntax": "critical", 
            "type_errors": "high",
            "missing_references": "medium",
            "warnings": "low",
            "other": "medium"
        }
        
        breakdown = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        for category, count in error_categories.items():
            # Ensure count is an integer, handle lists or other types
            if isinstance(count, (list, tuple)):
                count_val = len(count)
            elif isinstance(count, (int, float)):
                count_val = int(count)
            else:
                count_val = 1  # Default fallback
                
            priority = priority_mapping.get(category, "medium")
            breakdown[priority] += count_val
            
        return breakdown
    
    def _get_fix_priority_order(self, error_categories):
        """Get recommended order for fixing error categories"""
        priority_order = [
            "syntax",  # Fix syntax first
            "using_imports",  # Then imports
            "type_errors",  # Then type errors
            "missing_references",  # Then references
            "other",  # Then other issues
            "warnings"  # Finally warnings
        ]
        
        # Return only categories that have errors
        return [cat for cat in priority_order if self._get_category_count(error_categories, cat) > 0]
    
    def _get_category_count(self, error_categories, category):
        """Helper to safely get count from error categories"""
        count = error_categories.get(category, 0)
        if isinstance(count, (list, tuple)):
            return len(count)
        elif isinstance(count, (int, float)):
            return int(count)
        else:
            return 0
    
    def _extract_key_issues(self, error_categories):
        """Extract key issues from error categories"""
        key_issues = []
        
        if self._get_category_count(error_categories, "using_imports") > 0:
            key_issues.append("Missing or incorrect using directives")
        if self._get_category_count(error_categories, "syntax") > 0:
            key_issues.append("Syntax errors preventing compilation")
        if self._get_category_count(error_categories, "type_errors") > 0:
            key_issues.append("Type resolution and casting issues")
        if self._get_category_count(error_categories, "missing_references") > 0:
            key_issues.append("Missing assembly or package references")
            
        return key_issues or ["General compilation errors"]
    
    def _estimate_fix_time(self, total_errors, error_categories):
        """Estimate time needed to fix errors"""
        if total_errors <= 10:
            return "15-30 minutes"
        elif total_errors <= 50:
            return "1-2 hours"
        elif total_errors <= 100:
            return "2-4 hours"
        else:
            return "4+ hours"
    
    def _assess_complexity(self, error_categories):
        """Assess complexity of fixes needed"""
        using_imports = self._get_category_count(error_categories, "using_imports")
        syntax_errors = self._get_category_count(error_categories, "syntax")
        type_errors = self._get_category_count(error_categories, "type_errors")
        
        total_errors = sum(self._get_category_count(error_categories, cat) for cat in error_categories.keys())
        
        if total_errors == 0:
            return "No errors"
        elif using_imports > total_errors * 0.8:
            return "Low - Mostly import issues"
        elif syntax_errors > total_errors * 0.5:
            return "Medium - Significant syntax issues"
        elif type_errors > total_errors * 0.3:
            return "High - Complex type resolution needed"
        else:
            return "Medium - Mixed error types"
    
    def _generate_next_actions(self, consolidated_analysis):
        """Generate specific next actions for another agent"""
        actions = []
        
        step_plan = consolidated_analysis.get("step_by_step_plan", [])
        error_categories = consolidated_analysis.get("error_categories", {})
        
        # Add structured actions based on error types
        if self._get_category_count(error_categories, "using_imports") > 0:
            actions.append({
                "action": "fix_imports",
                "description": "Move all using directives to the top of C# files",
                "priority": "high",
                "estimated_time": "5-15 minutes",
                "automation_possible": True
            })
        
        if self._get_category_count(error_categories, "syntax") > 0:
            actions.append({
                "action": "fix_syntax",
                "description": "Resolve syntax errors in C# code",
                "priority": "critical", 
                "estimated_time": "30-60 minutes",
                "automation_possible": False
            })
        
        if self._get_category_count(error_categories, "missing_references") > 0:
            actions.append({
                "action": "add_references",
                "description": "Add missing package or assembly references",
                "priority": "medium",
                "estimated_time": "10-20 minutes", 
                "automation_possible": True
            })
        
        # Add general rebuild action
        actions.append({
            "action": "clean_rebuild",
            "description": "Run dotnet clean and dotnet build after fixes",
            "priority": "low",
            "estimated_time": "2-5 minutes",
            "automation_possible": True
        })
        
        return actions
